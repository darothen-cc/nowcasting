
import re
import glob
import pandas as pd
# from ccpy import wget

#: HRRR Regex
HRRR_PAT = (
    "hrrr/hrrr\."
    "(?P<year>\d{4})"
    "(?P<month>\d{2})"
    "(?P<day>\d{2})"
    "\.t(?P<hour>\d{2})z"
    "\.f(?P<fcst_hour>\d{2})"
    "\.grib2"
)
HRRR_RE = re.compile(HRRR_PAT)

#: Rectangular bounding box for region of interest
bounds = [-73.5, 40.0, -69.5, 44.0]

#: Time-range of interest
t_begin = pd.Timestamp(2017, 11, 3, 19)
t_end = pd.Timestamp(2017, 11, 3, 22)

PNGS = glob.glob("*/*.png", recursive=True)
NCS = [png.replace("png", "nc") for png in PNGS]

#: Iowa State Mesonet GIS archive
IEM_GIS_ROOT = (
    "https://mesonet.agron.iastate.edu/"
    "archive/data/{year:4d}/{month:02d}/{day:02d}/GIS/"
)
IEM_TIME_FMT = "%Y%m%d%H%M"
def to_iem_timestamp(s):
    return pd.Timestamp.strptime(s, IEM_TIME_FMT)

#: Set up raster datasets to download from IEM
#: 1) n0q
n0q_timesteps = pd.date_range(t_begin, t_end, freq='300S')
n0q_filename = ["n0q/n0q_{ts}.png".format(ts=x.strftime(IEM_TIME_FMT))
                for x in n0q_timesteps]

#: 2) a2m
a2m_timesteps = pd.date_range(t_begin, t_end, freq='120S')
a2m_filename = ["a2m/a2m_{ts}.png".format(ts=x.strftime(IEM_TIME_FMT))
                for x in a2m_timesteps]

#: 3) lcref
lcref_timesteps = pd.date_range(t_begin, t_end, freq='120S')
lcref_filename = ["lcref/lcref_{ts}.png".format(ts=x.strftime(IEM_TIME_FMT))
                  for x in lcref_timesteps]


def iem_raster_files(wildcards):
    """ Create the URLs corresponding to a given raster product on IEM's
    GIS archives. """

    product = wildcards['product']
    if product in ['a2m', 'lcref']:
        folder = 'mrms'
    else:
        folder = 'uscomp'

    ts = to_iem_timestamp(wildcards['ts'])

    base = (
        IEM_GIS_ROOT +
        "{folder}/{product}".format(folder=folder, product=product) +
        "_{year:4d}{month:02d}{day:02d}{hour:02d}{minute:02d}"
    )
    base = base.format(year=ts.year, month=ts.month, day=ts.day,
                       hour=ts.hour, minute=ts.minute)

    return [base+".png", base+".wld"]

rule download_from_iem:
    """ Download an archived raster product from IEM. """
    output:
        "{product}/{product}_{ts}.png", "{product}/{product}_{ts}.wld"
    params:
        inputs=iem_raster_files
    shell:
        """
        wget {params.inputs[0]} -O {output[0]}
        wget {params.inputs[1]} -O {output[1]}
        """

rule subset_png_to_nc:
    """ Subset a raster PNG/WLD file to a specific bounding box. """
    input:
        "{product}/{product}_{ts}.png"
    output:
        "{product}/{product}_{ts}.nc"
    run:
        import xarray as xr
        da = xr.open_rasterio(input[0])
        da.name = wildcards['product']

        # Subset the data - note that in the PNGs, y is reversed.
        da = da.sel(x=slice(bounds[0], bounds[2]),
                    y=slice(bounds[3], bounds[1]))
        da = da.isel(band=0)
        da.squeeze()

        # Promote to Dataset
        ds = da.to_dataset()
        ds = ds.expand_dims(['time', ])

        # Add a timestamp, and set encoding with correct granularity for units to
        # automatically propagate
        ts = to_iem_timestamp(wildcards['ts'])
        ds['time'] = [ts, ]
        ds['time'].encoding.update({'units': 'seconds since 2000-01-01 00:00:00'})

        # Write to disk
        ds.to_netcdf(output[0], unlimited_dims=['time', ],
                     encoding={wildcards['product']: {'complevel': 1, 'zlib': True}})

def png_to_nc(wildcards):
    """ Helper function to catalogue all png files and note them as netCDF """
    import glob
    product = wildcards['product']
    fns = sorted(glob.glob("{product}/{product}_*.png".format(product=product)))
    fns = [fn.replace(".png", ".nc") for fn in fns]
    return fns

rule concat_pngs:
    input: png_to_nc
    output: "{product}.subset.nc"
    shell:
        """
        ncrcat {input} {output[0]}
        """

# rule subset_gdal:
#     input:
#         "{product}/{product}_{ts}.png"
#     output:
#         "{product}/{product}_{ts}.nc"

rule download_hrrr:
    params:
        t_begin=t_begin,
        t_end=t_end
    script: "download_hrrr.py"

rule subset_hrrr:
    input: "hrrr/{basename}.grib2"
    output: "hrrr/{basename}.nc"
    run:
        import xarray as xr
        ds = xr.open_dataset(input[0], engine='pynio')
        ds = ds.rename({'gridlat_0': 'lat', 'gridlon_0': 'lon'})
        ds = ds[['lon', 'lat', 'PRATE_P0_L1_GLC0', 'REFD_P0_L103_GLC0',
                 'USTM_P0_2L103_GLC0', 'VSTM_P0_2L103_GLC0',
                 'UGRD_P0_L103_GLC0', 'VGRD_P0_L103_GLC0']]

        ll_lon, ll_lat, ur_lon, ur_lat = bounds
        ds = ds.where((ll_lat < ds.lat) & (ds.lat < ur_lat) &
                      (ll_lon < ds.lon) & (ds.lon < ur_lon), drop=True)
        ds = ds.sel(lv_HTGL8=1000.).squeeze()

        for v in ds.data_vars:
            ds[v].encoding = {'complevel': 1, 'zlib': True}

        # Capture the timestamp
        match = HRRR_RE.match(input[0])
        gd = match.groupdict()

        year = int(gd['year'])
        month = int(gd['month'])
        day = int(gd['day'])
        hour = int(gd['hour'])
        fcst_hour = int(gd['fcst_hour'])

        # Set up the ensemble info - timestamp and fcst run
        ds = ds.expand_dims(['fcst', 'time'])
        # ts = pd.Timestamp(year, month, day, hour+fcst_hour, 0, 0)
        # print(ts)
        ts = pd.Timestamp(year, month, day, hour+fcst_hour, 0, 0)
        ts_str = ts.strftime("%Y-%m-%d %H:00:00")
        ds['time'] = [ts, ]
        # ds['time'] = [fcst_hour, ]
        # ds['time'].attrs = {'units': 'hours since {}'.format(ts_str)}
        ds['fcst'] = [hour, ]

        print(ds['time'])
        print(ds['fcst'])

        ds.to_netcdf(output[0], unlimited_dims=['time', ])


def grib2_ens_to_netcdf(wildcards):
    """ Helper function to catalogue all grib2 files and note them as netCDF """
    import glob
    fns = glob.glob("hrrr/*.grib2")
    fns = [fn.replace(".grib2", ".nc") for fn in fns]
    return fns


rule concat_hrrr:
    input: grib2_ens_to_netcdf
    output:
        "hrrr/hrrr.ensemble.nc"
    run:
        import xarray as xr
        import glob

        fcst_ds = []
        for fcst in [18, 19, 20, 21, 22]:
            fns = sorted(glob.glob("hrrr/*.t{}z.*.nc".format(fcst)))
            dss = [xr.open_dataset(fn, decode_times=True) for fn in fns]
            try:
                ds = xr.concat(dss, 'time')
                fcst_ds.append(ds)
            except:
                continue
        ds = xr.concat(fcst_ds, 'fcst')

        ds.to_netcdf(output[0])


rule download_all:
    input:
        n0q_filename + a2m_filename + lcref_filename


rule all_pngs_to_ncs:
    input: NCS


rule all_concats:
    input:
        ["n0q.subset.nc", "a2m.subset.nc", "lcref.subset.nc"]


rule all_grib2_to_nc:
    input: dynamic("hrrr/{basename}.nc")
